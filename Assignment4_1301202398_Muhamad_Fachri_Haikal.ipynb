{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hklfach/Computer-Vision/blob/main/Assignment4_1301202398_Muhamad_Fachri_Haikal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npeh1DNhI3Nx"
      },
      "source": [
        "## 1301202398 - Muhamad Fachri Haikal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIIQR1EpJfSX"
      },
      "source": [
        "Perbandingan hasil klasifikasi data Cats vs Dogs menggunakan ekstraksi fitur HOG, LBP, dan SIFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sEWP2feJM8f"
      },
      "source": [
        "### Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu7UZTFMH3d9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage.feature import local_binary_pattern\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfHtejAVJT2G"
      },
      "source": [
        "### Download Dataset Cats vs Dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCSKuPl2KCzQ",
        "outputId": "e8ffeecf-3d66-4a95-b31e-2bc93aa9f31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-04-13 15:03:59--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.153.128, 142.250.145.128, 173.194.69.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.153.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘cats_and_dogs_filtered.zip’\n",
            "\n",
            "cats_and_dogs_filte 100%[===================>]  65.43M  29.8MB/s    in 2.2s    \n",
            "\n",
            "2023-04-13 15:04:01 (29.8 MB/s) - ‘cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O cats_and_dogs_filtered.zip\n",
        "    \n",
        "!unzip -q cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KorSBQE_Znjk"
      },
      "source": [
        "### Read Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjgLVTNgZsmz"
      },
      "outputs": [],
      "source": [
        "def read_images(path, label):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(path):\n",
        "        img = cv2.imread(os.path.join(path, filename))\n",
        "        img = cv2.resize(img, (150, 150))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "# read images and labels\n",
        "cat_path = \"cats_and_dogs_filtered/train/cats\"\n",
        "dog_path = \"cats_and_dogs_filtered/train/dogs\"\n",
        "cat_images, cat_labels = read_images(cat_path, 0)\n",
        "dog_images, dog_labels = read_images(dog_path, 1)\n",
        "\n",
        "# concatenate images and labels\n",
        "images = np.concatenate((cat_images, dog_images))\n",
        "labels = np.concatenate((cat_labels, dog_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHfRyJxsOk26"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQfy-rEYXBqM"
      },
      "outputs": [],
      "source": [
        "def extract_HOG(img):\n",
        "    hog = cv2.HOGDescriptor()\n",
        "    return hog.compute(img)\n",
        "\n",
        "def extract_LBP(img):\n",
        "    lbp = local_binary_pattern(img, 8, 2, method='default')\n",
        "    return lbp.flatten()\n",
        "\n",
        "def extract_SIFT(img):\n",
        "    sift = cv2.SIFT_create()\n",
        "    keypoints, descriptors = sift.detectAndCompute(img, None)\n",
        "    desc_samples = descriptors[np.random.randint(descriptors.shape[0], size=50)]\n",
        "    return desc_samples\n",
        "\n",
        "# extract features\n",
        "features_HOG = [extract_HOG(img) for img in images]\n",
        "features_LBP = [extract_LBP(img) for img in images]\n",
        "features_SIFT = [extract_SIFT(img) for img in images]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSQZoVBVcTbG"
      },
      "source": [
        "### Create Model with HOG\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9kdYIcemX-lh"
      },
      "outputs": [],
      "source": [
        "# split dataset into training and testing sets\n",
        "X_train_HOG, X_test_HOG, y_train_HOG, y_test_HOG = train_test_split(features_HOG, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# train and test using linear SVM\n",
        "svm_HOG = SVC()\n",
        "svm_HOG.fit(X_train_HOG, y_train_HOG)\n",
        "\n",
        "y_pred_HOG = svm_HOG.predict(X_test_HOG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bNQewoF6v4bE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7ae1df-674c-4092-f853-5528785f7a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.72      0.73       199\n",
            "           1       0.73      0.75      0.74       201\n",
            "\n",
            "    accuracy                           0.73       400\n",
            "   macro avg       0.73      0.73      0.73       400\n",
            "weighted avg       0.73      0.73      0.73       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_HOG, y_pred_HOG))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtG1sEEysQWX"
      },
      "source": [
        "### Create Model with LBP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehh0OemFsU2Z"
      },
      "outputs": [],
      "source": [
        "# split dataset into training and testing sets\n",
        "X_train_LBP, X_test_LBP, y_train_LBP, y_test_LBP = train_test_split(features_LBP, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# train and test using linear SVM\n",
        "svm_LBP = SVC()\n",
        "svm_LBP.fit(X_train_LBP, y_train_LBP)\n",
        "\n",
        "y_pred_LBP = svm_LBP.predict(X_test_LBP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYc1yqjh4Cby",
        "outputId": "21ec4734-553c-4c66-f5d2-6a29bc166aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.50      0.53       199\n",
            "           1       0.56      0.63      0.59       201\n",
            "\n",
            "    accuracy                           0.56       400\n",
            "   macro avg       0.57      0.56      0.56       400\n",
            "weighted avg       0.57      0.56      0.56       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_LBP, y_pred_LBP))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv8SxG1ZsZqM"
      },
      "source": [
        "### Create Model with SIFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtT7i3cDsfut"
      },
      "outputs": [],
      "source": [
        "# split dataset into training and testing sets\n",
        "X_train_SIFT, X_test_SIFT, y_train_SIFT, y_test_SIFT = train_test_split(features_SIFT, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_SIFT_1d = []\n",
        "for data in X_train_SIFT:\n",
        "  X_train_SIFT_1d.append(np.ravel(data))\n",
        "\n",
        "X_test_SIFT_1d = []\n",
        "for data in X_test_SIFT:\n",
        "  X_test_SIFT_1d.append(np.ravel(data))\n",
        "\n",
        "# train and test using linear SVM\n",
        "svm_SIFT = SVC()\n",
        "svm_SIFT.fit(X_train_SIFT_1d, y_train_SIFT)\n",
        "\n",
        "y_pred_SIFT = svm_SIFT.predict((X_test_SIFT_1d))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdKUgpfDOcvl",
        "outputId": "cbebcb35-ded3-4033-ee76-54708aebdeef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.57      0.59       199\n",
            "           1       0.60      0.63      0.62       201\n",
            "\n",
            "    accuracy                           0.60       400\n",
            "   macro avg       0.60      0.60      0.60       400\n",
            "weighted avg       0.60      0.60      0.60       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test_SIFT, y_pred_SIFT))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analisis"
      ],
      "metadata": {
        "id": "ntNa_Xlcabus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam hasil analisis ini, penggunaan ekstraksi fitur HOG menghasilkan akurasi yang lebih tinggi daripada ekstraksi fitur SIFT dan LBP untuk klasifikasi gambar kucing dan anjing menggunakan model SVM. Hal ini dapat disebabkan oleh beberapa faktor, di antaranya:\n",
        "\n",
        "1.   Ekstraksi fitur HOG bergantung pada gradien citra, sementara ekstraksi fitur SIFT dan LBP didasarkan pada keberadaan fitur-fitur lokal seperti tepi atau tekstur. Keterampilan pemrosesan citra ini mungkin berbeda-beda dalam kemampuan untuk membedakan antara kucing dan anjing, tergantung pada kualitas dataset dan variasi antara kucing dan anjing.\n",
        "2.   HOG menghasilkan deskripsi fitur yang lebih besar daripada SIFT atau LBP. Hal ini dapat memungkinkan SVM untuk mempelajari representasi fitur yang lebih baik dan dapat membedakan antara kelas kucing dan anjing dengan lebih baik. Ini juga ditandai dengan lamanya waktu saat melatih model dan memprediksinya menggunakan HOG.\n",
        "3.   Model SVM menggunakan pendekatan pembelajaran mesin yang berbeda dari model CNN, tetapi dalam kasus ini, SVM mungkin lebih cocok untuk dataset ini karena jumlah sampel yang relatif kecil dan kemampuan SVM untuk mengatasi masalah klasifikasi biner.\n",
        "\n",
        "Namun, perlu diingat bahwa hasil akurasi yang diperoleh mungkin tergantung pada parameter model dan parameter ekstraksi fitur yang digunakan, serta kualitas dataset yang digunakan. Oleh karena itu, perlu dilakukan pengujian lebih lanjut untuk menentukan metode ekstraksi fitur dan model yang paling cocok untuk dataset ini."
      ],
      "metadata": {
        "id": "LodT0-llaf23"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO9OUPR5p0oKwEDMWmh6qF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}